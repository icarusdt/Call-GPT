{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fgOxpmGrOvn"
      },
      "source": [
        "##### Copyright 2025 Google LLC."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mfk6YY3G5kqp"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTIfnvCn9HvH"
      },
      "source": [
        "### Setup your API key\n",
        "\n",
        "To run the following cell, your API key must be stored it in a Colab Secret named `GOOGLE_API_KEY`. If you don't already have an API key, or you're not sure how to create a Colab Secret, see [Authentication](../quickstarts/Authentication.ipynb) for an example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A1pkoyZb9Jm3"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5027929de8f"
      },
      "source": [
        "### Install and initialize the SDK\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "46zEFO2a9FFd"
      },
      "outputs": [],
      "source": [
        "!pip install -U -q \"google-genai>=1.16.0\" # 1.16 is needed for multi-speaker audio\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HghvVpbU0Uap"
      },
      "outputs": [],
      "source": [
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "client = genai.Client(api_key=GOOGLE_API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOov6dpG99rY"
      },
      "source": [
        "### Select a model\n",
        "\n",
        "Audio-out is only supported by the \"`tts`\" models, `gemini-2.5-flash-preview-tts` and `gemini-2.5-pro-preview-tts`.\n",
        "\n",
        "For more information about all Gemini models, check the [documentation](https://ai.google.dev/gemini-api/docs/models/gemini) for extended information on each of them.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "27Fikag0xSaB"
      },
      "outputs": [],
      "source": [
        "MODEL_ID = \"gemini-2.5-flash-preview-tts\" # @param [\"gemini-2.5-flash-preview-tts\",\"gemini-2.5-pro-preview-tts\"] {\"allow-input\":true, isTemplate: true}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_XlihP2FZeg"
      },
      "source": [
        "Next create a helper function to prompt the model and play back the audio in the notebook:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "uwY8N8_YBrQn"
      },
      "outputs": [],
      "source": [
        "# @title Helper functions (just run that cell)\n",
        "\n",
        "import contextlib\n",
        "import wave\n",
        "from IPython.display import Audio\n",
        "\n",
        "file_index = 0\n",
        "\n",
        "@contextlib.contextmanager\n",
        "def wave_file(filename, channels=1, rate=24000, sample_width=2):\n",
        "    with wave.open(filename, \"wb\") as wf:\n",
        "        wf.setnchannels(channels)\n",
        "        wf.setsampwidth(sample_width)\n",
        "        wf.setframerate(rate)\n",
        "        yield wf\n",
        "\n",
        "def play_audio_blob(blob):\n",
        "  global file_index\n",
        "  file_index += 1\n",
        "\n",
        "  fname = f'audio_{file_index}.wav'\n",
        "  with wave_file(fname) as wav:\n",
        "    wav.writeframes(blob.data)\n",
        "\n",
        "  return Audio(fname, autoplay=True)\n",
        "\n",
        "def play_audio(response):\n",
        "    return play_audio_blob(response.candidates[0].content.parts[0].inline_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8okc98mP4Fjw"
      },
      "source": [
        "## Control how the model speaks\n",
        "\n",
        "There are 30 different built-in voices you can use and 24 supported languages which gives you plenty of combinations to try."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOAHrb6wCxy7"
      },
      "source": [
        "### Choose a voice\n",
        "\n",
        "Choose a voice among the 30 different ones. You can find their characteristics in the [documentation](https://ai.google.dev/gemini-api/docs/speech-generation#voices)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z32vkVi0F14F"
      },
      "outputs": [],
      "source": [
        "voice_name = \"Charon\" # @param [\"Zephyr\", \"Puck\", \"Charon\", \"Kore\", \"Fenrir\", \"Leda\", \"Orus\", \"Aoede\", \"Callirhoe\", \"Autonoe\", \"Enceladus\", \"Iapetus\", \"Umbriel\", \"Algieba\", \"Despina\", \"Erinome\", \"Algenib\", \"Rasalgethi\", \"Laomedeia\", \"Achernar\", \"Alnilam\", \"Schedar\", \"Gacrux\", \"Pulcherrima\", \"Achird\", \"Zubenelgenubi\", \"Vindemiatrix\", \"Sadachbia\", \"Sadaltager\", \"Sulafar\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pyb8MZRM69su"
      },
      "source": [
        "### Change the language\n",
        "\n",
        "Just tell the model to speak in a certain language and it will. The [documentation](https://ai.google.dev/gemini-api/docs/speech-generation#languages) lists all the supported ones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "NlF5ZyabJ8bV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "33b651bd-3f19-4f2e-903c-935dcfb9d57b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_30dec36a-c0c9-4b78-ba92-1e3d68d659d1\", \"audio_2.wav\", 175290)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "response = client.models.generate_content(\n",
        "  model=MODEL_ID,\n",
        "  contents=\"\"\"\n",
        "    Speak in a warm, experienced voice, in Vietnamese:\n",
        "    \"Người chủ nhà hàng nhượng quyền đã làm một điều mà người chủ nhà hàng đơn lẻ không thể.\"\n",
        "\n",
        "  \"\"\",\n",
        "  config={\n",
        "      \"response_modalities\": ['Audio'],\n",
        "      \"speech_config\": {\n",
        "          \"voice_config\": {\n",
        "              \"prebuilt_voice_config\": {\n",
        "                  \"voice_name\": voice_name\n",
        "              }\n",
        "          }\n",
        "      }\n",
        "  },\n",
        ")\n",
        "files.download(fname)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download âm thanh"
      ],
      "metadata": {
        "id": "E4LMpFgbCtVl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: chọn đầu vào là file text, chia file text thành nhiều đoạn mỗi đoạn 1429 từ. sau đó chuyển văn bản thành giọng nói. đặt tên file theo tên file text\n",
        "\n",
        "# Function to split text into chunks\n",
        "def split_text_into_chunks(text, chunk_size=1429):\n",
        "    words = text.split()\n",
        "    return [\" \".join(words[i:i + chunk_size]) for i in range(0, len(words), chunk_size)]\n",
        "\n",
        "# Upload the text file\n",
        "uploaded = files.upload()\n",
        "\n",
        "for filename in uploaded.keys():\n",
        "    with open(filename, 'r', encoding='utf-8') as f:\n",
        "        text = f.read()\n",
        "\n",
        "    chunks = split_text_into_chunks(text)\n",
        "    base_filename = filename.rsplit('.', 1)[0]\n",
        "\n",
        "    for i, chunk in enumerate(chunks):\n",
        "        print(f\"Processing chunk {i+1}/{len(chunks)}\")\n",
        "        response = client.models.generate_content(\n",
        "            model=MODEL_ID,\n",
        "            contents=f\"\"\"\n",
        "              Speak in a warm, experienced voice, in Vietnamese:\n",
        "              \"{chunk}\"\n",
        "\n",
        "            \"\"\",\n",
        "            config={\n",
        "                \"response_modalities\": ['Audio'],\n",
        "                \"speech_config\": {\n",
        "                    \"voice_config\": {\n",
        "                        \"prebuilt_voice_config\": {\n",
        "                            \"voice_name\": voice_name\n",
        "                        }\n",
        "                    }\n",
        "                }\n",
        "            },\n",
        "        )\n",
        "\n",
        "        # Get the audio blob\n",
        "        audio_blob = response.candidates[0].content.parts[0].inline_data\n",
        "\n",
        "        # Define the output filename\n",
        "        output_fname = f'{base_filename}_part_{i+1}.wav'\n",
        "\n",
        "        # Write the audio data to a wave file\n",
        "        with wave_file(output_fname) as wav:\n",
        "            wav.writeframes(audio_blob.data)\n",
        "\n",
        "        print(f\"Saved chunk {i+1} as {output_fname}\")\n",
        "\n",
        "        # Download the audio file\n",
        "        files.download(output_fname)"
      ],
      "metadata": {
        "id": "h8zyBx8LGJYv"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "0fgOxpmGrOvn"
      ],
      "name": "Get_started_TTS.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}